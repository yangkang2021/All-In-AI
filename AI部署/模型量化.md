# 模型量化
1. ncnn的模型量化
    - https://github.com/Tencent/ncnn/wiki/quantized-int8-inference
    - https://zhuanlan.zhihu.com/p/370689914
    - k2的ncnn的int8量化:https://github.com/k2-fsa/sherpa-ncnn/blob/master/sherpa-ncnn/csrc/generate-int8-scale-table.cc
    - k2的ncnn的int8量化:https://huggingface.co/csukuangfj/sherpa-ncnn-conv-emformer-transducer-2022-12-04/tree/main
   - https://zhuanlan.zhihu.com/p/387072703
   - https://zhuanlan.zhihu.com/p/279281082
   - https://zhuanlan.zhihu.com/p/58182172
2. onnx的模型量化
   - onnx simplifier 和 optimizer： https://zhuanlan.zhihu.com/p/350702340
   - 官方文档：https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html
   
3. ggml的int4量化


4. k2的量化
